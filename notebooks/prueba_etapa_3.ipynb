{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Algunos astronautas dejaron olvidadas sus herramientas de trabajo fuera de la estaci√≥n.\n",
    "# Proponen usar al robot para localizarlas. Utilizando funciones de movilidad de la etapa anterior\n",
    "# Revisar coordenadas donde los astronautas trabajaron y  mostrar en rviz la tf de las ubicaciones de tantos objetos como puedan encontrar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "ja"
   },
   "source": [
    "## El primer astronauta reporta haber trabajado en las coordenadas (1.25 , 1)\n",
    "# Hay un aproximado de 4 herramientas faltantes cerca de las coordenadas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Import the required libraries and initialize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from std_srvs.srv import Empty, Trigger, TriggerRequest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "import rospy\n",
    "#import cv2\n",
    "import ros_numpy\n",
    "import numpy as np\n",
    "#from tmc_tabletop_segmentator.srv import TabletopSegmentation\n",
    "#from tmc_tabletop_segmentator.srv import TabletopSegmentationRequest Tmc tabletop deprecated\n",
    "from sensor_msgs.msg import Image\n",
    "from std_msgs.msg import String\n",
    "import tf\n",
    "import tf2_ros\n",
    "import geometry_msgs.msg\n",
    "from utils_notebooks import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ros_numpy\n",
    "import rospy\n",
    "import tf\n",
    "from gazebo_ros import gazebo_interface\n",
    "from sensor_msgs.msg import LaserScan, PointCloud2\n",
    "from geometry_msgs.msg import Pose, Quaternion ,TransformStamped\n",
    "import moveit_commander\n",
    "import moveit_msgs.msg\n",
    "\n",
    "import sys\n",
    "\n",
    "from utils_notebooks import *\n",
    "#from utils_task1 import *\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "ja"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5.5'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "cv2.__version__\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "{",
     "\"tags\":",
     "[",
     "\"hide-cell\"",
     "]",
     "}"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1662250579.321607833, 2990.732000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 2990.762000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250616.921185097, 3005.459000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3005.459000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250622.910132166, 3007.833000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 2990.762000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250622.946730950, 3007.843000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3005.459000 according to authority /pose_integrator\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "bridge = CvBridge()\n",
    "###might take some time to load all those takeshi meshes in rviz\n",
    "\n",
    "head = moveit_commander.MoveGroupCommander('head')\n",
    "arm = moveit_commander.MoveGroupCommander('arm')\n",
    "whole_body = moveit_commander.MoveGroupCommander('whole_body_light')\n",
    "whole_body.set_workspace([-6.0, -6.0, 6.0, 6.0])#whole_body.go(wb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_spawned(num_objs):\n",
    "    for i in range (num_objs):\n",
    "        delete_object('spawned'+str(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot_to_euler(R):\n",
    "    import sys\n",
    "    import math as m\n",
    "    tol = sys.float_info.epsilon * 10\n",
    "\n",
    "    if abs(R.item(0,0))< tol and abs(R.item(1,0)) < tol:\n",
    "       eul1 = 0\n",
    "       eul2 = m.atan2(-R.item(2,0), R.item(0,0))\n",
    "       eul3 = m.atan2(-R.item(1,2), R.item(1,1))\n",
    "    else:   \n",
    "       eul1 = m.atan2(R.item(1,0),R.item(0,0))\n",
    "       sp = m.sin(eul1)\n",
    "       cp = m.cos(eul1)\n",
    "       eul2 = m.atan2(-R.item(2,0),cp*R.item(0,0)+sp*R.item(1,0))\n",
    "       eul3 = m.atan2(sp*R.item(0,2)-cp*R.item(1,2),cp*R.item(1,1)-sp*R.item(0,1))\n",
    "\n",
    "    return np.asarray((eul1,eul2,eul3))\n",
    "def pca_xyz(xyz):\n",
    "    quats=[]\n",
    "    for i in range( len(xyz)):\n",
    "        pca= PCA(n_components=3).fit(xyz[i])\n",
    "        vec0= pca.components_[0,:]\n",
    "        vec1= pca.components_[1,:]\n",
    "        vec2= pca.components_[2,:]\n",
    "        R=pca.components_\n",
    "        euler=rot_to_euler(R)\n",
    "        quats.append(tf.transformations.quaternion_from_euler(euler[0],euler[1],euler[2]))\n",
    "    return quats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot_to_euler(R):\n",
    "    import sys\n",
    "    tol = sys.float_info.epsilon * 10\n",
    "\n",
    "    if abs(R.item(0,0))< tol and abs(R.item(1,0)) < tol:\n",
    "       eul1 = 0\n",
    "       eul2 = m.atan2(-R.item(2,0), R.item(0,0))\n",
    "       eul3 = m.atan2(-R.item(1,2), R.item(1,1))\n",
    "    else:   \n",
    "       eul1 = m.atan2(R.item(1,0),R.item(0,0))\n",
    "       sp = m.sin(eul1)\n",
    "       cp = m.cos(eul1)\n",
    "       eul2 = m.atan2(-R.item(2,0),cp*R.item(0,0)+sp*R.item(1,0))\n",
    "       eul3 = m.atan2(sp*R.item(0,2)-cp*R.item(1,2),cp*R.item(1,1)-sp*R.item(0,1))\n",
    "\n",
    "    return np.asarray((eul1,eul2,eul3))\n",
    "def pca_xyz(xyz):\n",
    "    quats=[]\n",
    "    for i in range( len(xyz)):\n",
    "        pca= PCA(n_components=3).fit(xyz[i])\n",
    "        vec0= pca.components_[0,:]\n",
    "        vec1= pca.components_[1,:]\n",
    "        vec2= pca.components_[2,:]\n",
    "        R=pca.components_\n",
    "        euler=rot_to_euler(R)\n",
    "        quats.append(tf.transformations.quaternion_from_euler(euler[0],euler[1],euler[2]))\n",
    "    return quats\n",
    "def static_tf_publish(cents, quaternions=[],label=''):\n",
    "    if (len(quaternions))==0:\n",
    "        quats=np.zeros((len(cents),4)) \n",
    "        quats[:,3]=1\n",
    "        #print quats\n",
    "    else:\n",
    "        quats=np.asarray(quaternions)\n",
    "        #print quats\n",
    "    for  i ,cent  in enumerate(cents):\n",
    "        x,y,z=cent\n",
    "        if np.isnan(x) or np.isnan(y) or np.isnan(z):\n",
    "            print('nan , rejected')\n",
    "        else:\n",
    "            #### first place a dissolving tf wrt head sensor  in centroids\n",
    "\n",
    "            broadcaster.sendTransform((x,y,z),(0,0,0,1), rospy.Time.now(), 'Object'+str(i),\"head_rgbd_sensor_link\")\n",
    "            rospy.sleep(.2)\n",
    "            \n",
    "            #### then place each centr wrt map\n",
    "            xyz_map,cent_quat= listener.lookupTransform('/map', 'Object'+str(i),rospy.Time(0))\n",
    "            map_euler=tf.transformations.euler_from_quaternion(cent_quat)\n",
    "            rospy.sleep(.2)\n",
    "            static_transformStamped = TransformStamped()\n",
    "\n",
    "            ##FIXING TF TO MAP ( ODOM REALLY)    \n",
    "            #tf_broadcaster1.sendTransform( (xyz[0],xyz[1],xyz[2]),tf.transformations.quaternion_from_euler(0, 0, 0), rospy.Time.now(), \"obj\"+str(ind), \"head_rgbd_sensor_link\")\n",
    "            ## Finally boiradcast a static tf  in cents and with quaternion found  in pca\n",
    "            if xyz_map[-1] <.2:\n",
    "                static_transformStamped.header.stamp = rospy.Time.now()\n",
    "                static_transformStamped.header.frame_id = \"map\"\n",
    "                static_transformStamped.child_frame_id = \"Floor_Object\"+str(i)+label \n",
    "                static_transformStamped.transform.translation.x = float(xyz_map[0])\n",
    "                static_transformStamped.transform.translation.y = float(xyz_map[1])\n",
    "                static_transformStamped.transform.translation.z = float(xyz_map[2])\n",
    "                #quat = tf.transformations.quaternion_from_euler(-euler[0],0,1.5)\n",
    "                static_transformStamped.transform.rotation.x = quats [i,0]#-quat[0]#trans.transform.rotation.x\n",
    "                static_transformStamped.transform.rotation.y = quats [i,1]#-quat[1]#trans.transform.rotation.y\n",
    "                static_transformStamped.transform.rotation.z = quats [i,2]#-quat[2]#trans.transform.rotation.z\n",
    "                static_transformStamped.transform.rotation.w = quats [i,3]#-quat[3]#trans.transform.rotation.w\n",
    "\n",
    "\n",
    "                tf_static_broadcaster.sendTransform(static_transformStamped)\n",
    "                print ('images[]',i)\n",
    "            if    (xyz_map[-1] >.4)and (xyz_map[-1] <.5):\n",
    "                static_transformStamped.header.stamp = rospy.Time.now()\n",
    "                static_transformStamped.header.frame_id = \"map\"\n",
    "                static_transformStamped.child_frame_id = \"Table_Object\"+str(i)+label \n",
    "                static_transformStamped.transform.translation.x = float(xyz_map[0])\n",
    "                static_transformStamped.transform.translation.y = float(xyz_map[1])\n",
    "                static_transformStamped.transform.translation.z = float(xyz_map[2])\n",
    "                #quat = tf.transformations.quaternion_from_euler(-euler[0],0,1.5)\n",
    "                static_transformStamped.transform.rotation.x = quats [i,0]#-quat[0]#trans.transform.rotation.x\n",
    "                static_transformStamped.transform.rotation.y = quats [i,1]#-quat[1]#trans.transform.rotation.y\n",
    "                static_transformStamped.transform.rotation.z = quats [i,2]#-quat[2]#trans.transform.rotation.z\n",
    "                static_transformStamped.transform.rotation.w = quats [i,3]#-quat[3]#trans.transform.rotation.w\n",
    "\n",
    "\n",
    "                tf_static_broadcaster.sendTransform(static_transformStamped)\n",
    "                print ('images[]',i)\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python /home/oscar/Codes/catkin_mio_ws/src/hsrb_samples/hsrb_vision_samples/src/hsrb_vision_samples/execute_tabletop_segmentation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python /home/oscar/Codes/catkin_mio_ws/src/hsrb_samples/hsrb_vision_samples/src/hsrb_vision_samples/execute_tabletop_segmentation_backup.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rospy.init_node(\"recognition\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbd = RGBD()\n",
    "listener = tf.TransformListener()# tf 2 to do\n",
    "broadcaster= tf.TransformBroadcaster()# tf2 to do\n",
    "tf_static_broadcaster= tf2_ros.StaticTransformBroadcaster()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaze_point(x,y,z):\n",
    "    \n",
    "    \n",
    "    \n",
    "    head_pose = head.get_current_joint_values()\n",
    "    head_pose[0]=0.0\n",
    "    head_pose[1]=0.0\n",
    "    head.set_joint_value_target(head_pose)\n",
    "    head.go()\n",
    "    \n",
    "    trans , rot = listener.lookupTransform('/map', '/head_rgbd_sensor_gazebo_frame', rospy.Time(0)) #\n",
    "    \n",
    "    arm_pose=arm.get_current_joint_values()\n",
    "    arm_pose[0]=.1\n",
    "    arm_pose[1]= -0.3\n",
    "    arm.set_joint_value_target(arm_pose)\n",
    "    arm.go()\n",
    "    \n",
    "    e =tf.transformations.euler_from_quaternion(rot)\n",
    "    print('i am at',trans,np.rad2deg(e)[2])\n",
    "    print('gaze goal',x,y,z)\n",
    "    #tf.transformations.euler_from_quaternion(rot)\n",
    "\n",
    "\n",
    "    x_rob,y_rob,z_rob,th_rob= trans[0], trans[1] ,trans[2] ,  e[2]\n",
    "\n",
    "\n",
    "    D_x=x_rob-x\n",
    "    D_y=y_rob-y\n",
    "    D_z=z_rob-z\n",
    "\n",
    "    D_th= np.arctan2(D_y,D_x)\n",
    "    print('relative to robot',(D_x,D_y,np.rad2deg(D_th)))\n",
    "\n",
    "    pan_correct= (- th_rob + D_th + np.pi) % (2*np.pi)\n",
    "\n",
    "    if(pan_correct > np.pi):\n",
    "        pan_correct=-2*np.pi+pan_correct\n",
    "    if(pan_correct < -np.pi):\n",
    "        pan_correct=2*np.pi+pan_correct\n",
    "\n",
    "    if ((pan_correct) > .5 * np.pi):\n",
    "        print ('Exorcist alert')\n",
    "        pan_correct=.5*np.pi\n",
    "    head_pose[0]=pan_correct\n",
    "    tilt_correct=np.arctan2(D_z,np.linalg.norm((D_x,D_y)))\n",
    "\n",
    "    head_pose [1]=-tilt_correct\n",
    "    \n",
    "    \n",
    "    \n",
    "    head.set_joint_value_target(head_pose)\n",
    "    succ=head.go()\n",
    "    return succ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_octo_client = rospy.ServiceProxy('/clear_octomap', Empty)\n",
    "\n",
    "clear_octo_client.wait_for_service(timeout=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize ROS publisher\n",
    "pub = rospy.Publisher('goal', PoseStamped, queue_size=10)\n",
    "goal = MoveBaseGoal()\n",
    "navclient = actionlib.SimpleActionClient('/move_base/move', MoveBaseAction)\n",
    "    \n",
    "# wait to establish connection between the navigation interface\n",
    "# move_base and navigation_log_recorder node\n",
    "def move_base(goal_x,goal_y,goal_yaw,time_out=10):\n",
    "    pose = PoseStamped()\n",
    "    pose.header.stamp = rospy.Time.now()\n",
    "    pose.header.frame_id = \"map\"\n",
    "    pose.pose.position = Point(goal_x, goal_y, 0)\n",
    "    quat = tf.transformations.quaternion_from_euler(0, 0, goal_yaw)\n",
    "    pose.pose.orientation = Quaternion(*quat)\n",
    "\n",
    "\n",
    "    # create a MOVE BASE GOAL\n",
    "    goal = MoveBaseGoal()\n",
    "    goal.target_pose = pose\n",
    "\n",
    "    # send message to the action server\n",
    "    navclient.send_goal(goal)\n",
    "\n",
    "    # wait for the action server to complete the order\n",
    "    navclient.wait_for_result(timeout=rospy.Duration(time_out))\n",
    "\n",
    "    # print result of navigation\n",
    "    action_state = navclient.get_state()\n",
    "    return navclient.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_pca(lower=2000,higher=50000,reg_ly=0,reg_hy=1000,plt_images=False): \n",
    "    image= rgbd.get_h_image()\n",
    "    iimmg= rgbd.get_image()\n",
    "    points_data= rgbd.get_points()\n",
    "    values=image.reshape((-1,3))\n",
    "    values= np.float32(values)\n",
    "    criteria= (  cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER  ,1000,0.1)\n",
    "    k=6\n",
    "    _ , labels , cc =cv2.kmeans(values , k ,None,criteria,30,cv2.KMEANS_RANDOM_CENTERS)\n",
    "    cc=np.uint8(cc)\n",
    "    segmented_image= cc[labels.flatten()]\n",
    "    segmented_image=segmented_image.reshape(image.shape)\n",
    "    th3 = cv2.adaptiveThreshold(segmented_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    im4=cv2.erode(th3,kernel,iterations=4)\n",
    "    plane_mask=points_data['z']\n",
    "    cv2_img=plane_mask.astype('uint8')\n",
    "    img=im4\n",
    "    contours, hierarchy = cv2.findContours(im4.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i=0\n",
    "    cents=[]\n",
    "    points=[]\n",
    "    images=[]\n",
    "    for i, contour in enumerate(contours):\n",
    "        \n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        if area > lower and area < higher :\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            \n",
    "    \n",
    "            boundRect = cv2.boundingRect(contour)\n",
    "            #just for drawing rect, dont waste too much time on this\n",
    "            image_aux= iimmg[boundRect[1]:boundRect[1]+boundRect[3],boundRect[0]:boundRect[0]+boundRect[2]]\n",
    "            images.append(image_aux)\n",
    "            img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (0,0,0), 2)\n",
    "            # calculate moments for each contour\n",
    "            if (cY > reg_ly and cY < reg_hy  ):\n",
    "                \n",
    "                cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "                cv2.putText(img, \"centroid_\"+str(i)+\"_\"+str(cX)+','+str(cY)    ,    (cX - 25, cY - 25)   ,cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "                print ('cX,cY',cX,cY)\n",
    "                xyz=[]\n",
    "\n",
    "\n",
    "                for jy in range (boundRect[0], boundRect[0]+boundRect[2]):\n",
    "                    for ix in range(boundRect[1], boundRect[1]+boundRect[3]):\n",
    "                        aux=(np.asarray((points_data['x'][ix,jy],points_data['y'][ix,jy],points_data['z'][ix,jy])))\n",
    "                        if np.isnan(aux[0]) or np.isnan(aux[1]) or np.isnan(aux[2]):\n",
    "                            'reject point'\n",
    "                        else:\n",
    "                            xyz.append(aux)\n",
    "\n",
    "                xyz=np.asarray(xyz)\n",
    "                cent=xyz.mean(axis=0)\n",
    "                cents.append(cent)\n",
    "                print (cent)\n",
    "                points.append(xyz)\n",
    "            else:\n",
    "                print ('cent out of region... rejected')\n",
    "    sub_plt=0\n",
    "    if plt_images:\n",
    "        for image in images:\n",
    "\n",
    "            sub_plt+=1\n",
    "            ax = plt.subplot(5, 5, sub_plt )\n",
    "\n",
    "            plt.imshow(image)\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    cents=np.asarray(cents)\n",
    "    ### returns centroids found and a group of 3d coordinates that conform the centroid\n",
    "    return(cents,np.asarray(points), images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_square_imgs(lower=2000,higher=50000,reg_ly=0,reg_hy=1000,reg_lx=0,reg_hx=1000,plt_images=False): \n",
    "\n",
    "    #Using kmeans for image segmentation find\n",
    "    #Lower, higher = min, max area of the box\n",
    "    #reg_ly= 30,reg_hy=600,reg_lx=0,reg_hx=1000,    Region (low  x,y  region high x,y ) Only centroids within region are accepted\n",
    "    image= rgbd.get_h_image()\n",
    "    iimmg= rgbd.get_image()\n",
    "    points_data= rgbd.get_points()\n",
    "    values=image.reshape((-1,3))\n",
    "    values= np.float32(values)\n",
    "    criteria= (  cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER  ,1000,0.1)\n",
    "    k=6\n",
    "    _ , labels , cc =cv2.kmeans(values , k ,None,criteria,30,cv2.KMEANS_RANDOM_CENTERS)\n",
    "    cc=np.uint8(cc)\n",
    "    segmented_image= cc[labels.flatten()]\n",
    "    segmented_image=segmented_image.reshape(image.shape)\n",
    "    th3 = cv2.adaptiveThreshold(segmented_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    im4=cv2.erode(th3,kernel,iterations=4)\n",
    "    plane_mask=points_data['z']\n",
    "    cv2_img=plane_mask.astype('uint8')\n",
    "    img=im4\n",
    "    contours, hierarchy = cv2.findContours(im4.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i=0\n",
    "    cents=[]\n",
    "    points=[]\n",
    "    images=[]\n",
    "    for i, contour in enumerate(contours):\n",
    "\n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        if area > lower and area < higher :\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "\n",
    "            boundRect = cv2.boundingRect(contour)\n",
    "            #just for drawing rect, dont waste too much time on this\n",
    "            image_aux= iimmg[boundRect[1]:boundRect[1]+max(boundRect[3],boundRect[2]),boundRect[0]:boundRect[0]+max(boundRect[3],boundRect[2])]\n",
    "            images.append(image_aux)\n",
    "            img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (0,0,0), 2)\n",
    "            #img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+max(boundRect[2],boundRect[3]), boundRect[1]+max(boundRect[2],boundRect[3])), (0,0,0), 2)\n",
    "            # calculate moments for each contour\n",
    "            if (cY > reg_ly and cY < reg_hy and  cX > reg_lx and cX < reg_hx   ):\n",
    "\n",
    "                cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "                cv2.putText(img, \"centroid_\"+str(i)+\"_\"+str(cX)+','+str(cY)    ,    (cX - 25, cY - 25)   ,cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "                #print ('cX,cY',cX,cY)\n",
    "                xyz=[]\n",
    "\n",
    "\n",
    "                for jy in range (boundRect[0], boundRect[0]+boundRect[2]):\n",
    "                    for ix in range(boundRect[1], boundRect[1]+boundRect[3]):\n",
    "                        aux=(np.asarray((points_data['x'][ix,jy],points_data['y'][ix,jy],points_data['z'][ix,jy])))\n",
    "                        if np.isnan(aux[0]) or np.isnan(aux[1]) or np.isnan(aux[2]):\n",
    "                            'reject point'\n",
    "                        else:\n",
    "                            xyz.append(aux)\n",
    "\n",
    "                xyz=np.asarray(xyz)\n",
    "                cent=xyz.mean(axis=0)\n",
    "                cents.append(cent)\n",
    "                #print (cent)\n",
    "                points.append(xyz)\n",
    "            else:\n",
    "                #print ('cent out of region... rejected')\n",
    "                images.pop()\n",
    "    sub_plt=0\n",
    "    if plt_images:\n",
    "        for image in images:\n",
    "\n",
    "            sub_plt+=1\n",
    "            ax = plt.subplot(5, 5, sub_plt )\n",
    "\n",
    "            plt.imshow(image)\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    cents=np.asarray(cents)\n",
    "    #images.append(img)\n",
    "    return(cents,np.asarray(points), images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_to_cents(res, plt_images=False):\n",
    "    objs_depth_centroids=[]\n",
    "    xyz=[]\n",
    "    images=[]\n",
    "    for i in range (len(res.segmented_objects_array.table_objects_array\t)):\n",
    "        print ( 'Plane',i,'has', len(res.segmented_objects_array.table_objects_array[i].depth_image_array), 'objects')\n",
    "        for j in range (len(res.segmented_objects_array.table_objects_array[i].points_array)):\n",
    "            cv2_img_depth = bridge.imgmsg_to_cv2(res.segmented_objects_array.table_objects_array[i].depth_image_array[0] )\n",
    "            cv2_img = bridge.imgmsg_to_cv2(res.segmented_objects_array.table_objects_array[i].rgb_image_array[j],\"rgb8\" )\n",
    "            pc= ros_numpy.numpify (res.segmented_objects_array.table_objects_array[i].points_array[j])\n",
    "            points=np.zeros((pc.shape[0],3))\n",
    "            points[:,0]=pc['x']\n",
    "            points[:,1]=pc['y']\n",
    "            points[:,2]=pc['z']\n",
    "\n",
    "            points_mean=np.mean(points,axis=0)\n",
    "            if np.isnan(points_mean).max():\n",
    "                print('nan reject')\n",
    "            else:\n",
    "\n",
    "                objs_depth_centroids.append(points_mean)\n",
    "                xyz.append(points)\n",
    "                images.append(cv2_img)\n",
    "\n",
    "    print (objs_depth_centroids)\n",
    "\n",
    "    #lets publish a tf to this centroids ( lot of false positives) !!!!\n",
    "    sub_plt=0\n",
    "    if plt_images:\n",
    "        for image in images:\n",
    "\n",
    "            sub_plt+=1\n",
    "            ax = plt.subplot(5, 5, sub_plt )\n",
    "\n",
    "            plt.imshow(image)\n",
    "            plt.axis(\"off\")\n",
    "    return(np.asarray(objs_depth_centroids), np.asarray(xyz),images)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1662250626.865920042, 3009.316000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3009.337000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250626.866005075, 3009.316000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3009.337000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250626.868526215, 3009.328000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3009.337000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250628.813291317, 3010.103000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3010.144000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250628.813355949, 3010.103000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3010.144000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250628.814469350, 3010.144000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3010.144000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250630.500567948, 3010.761000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3010.788000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250630.500739509, 3010.761000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3010.788000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250630.504519840, 3010.761000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3010.788000 according to authority unknown_publisher\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm.set_named_target('go')\n",
    "arm.go()\n",
    "head_val=head.get_current_joint_values()\n",
    "#head_val[0]=np.deg2rad(0)\n",
    "head_val[1]=np.deg2rad(-45)\n",
    "\n",
    "head.go(head_val)\n",
    "#If head didnt move, MOVE IT isnt running  properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "_path_model = \"/home/roboworks/catkin_extras/src/tmc_wrs_gazebo_world/models\"     \n",
    "objs=os.listdir(_path_model)\n",
    "objs.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1662250668.440689519, 3026.006000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3026.049000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250668.440771255, 3026.006000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3026.049000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250668.452601888, 3026.049000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3026.049000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250686.931246894, 3033.244000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3033.279000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250686.931329916, 3033.244000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3033.279000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250686.931554081, 3033.244000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3033.279000 according to authority unknown_publisher\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am at [1.3104435681151938, 0.9873574843047224, 0.9670981639207188] -179.97855085151818\n",
      "gaze goal 0.0 1.2 0.0\n",
      "relative to robot (1.3104435681151938, -0.2126425156952776, -9.216912069144906)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1662250708.592852426, 3041.776000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3041.776000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250708.592950082, 3041.776000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3041.776000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250708.592996645, 3041.776000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3041.776000 according to authority /pose_integrator\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move_base(1.25,1.0,np.pi)\n",
    "gaze_point(0.0,1.2,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1662250729.364128, 3049.986000]: Spawn: ycb_057_racquetball\n",
      "[INFO] [1662250729.370859, 3049.986000]: Spawn: [-0.16824031  0.67658719  0.59236072  0.40377438]\n",
      "[INFO] [1662250729.374868, 3049.986000]: Waiting for service /gazebo/spawn_sdf_model\n",
      "[INFO] [1662250729.379455, 3049.986000]: Calling service /gazebo/spawn_sdf_model\n",
      "[INFO] [1662250729.663245, 3050.071000]: Spawn status: SpawnModel: Successfully spawned entity\n",
      "[INFO] [1662250729.666631, 3050.071000]: Spawn: ycb_057_racquetball\n",
      "[INFO] [1662250729.672820, 3050.072000]: Spawn: [0.04440329 0.57082831 0.81547116 0.08479495]\n",
      "[INFO] [1662250729.678405, 3050.075000]: Waiting for service /gazebo/spawn_sdf_model\n",
      "[INFO] [1662250729.685364, 3050.079000]: Calling service /gazebo/spawn_sdf_model\n",
      "[INFO] [1662250729.915711, 3050.149000]: Spawn status: SpawnModel: Successfully spawned entity\n",
      "[INFO] [1662250729.923158, 3050.149000]: Spawn: ycb_057_racquetball\n",
      "[INFO] [1662250729.925298, 3050.149000]: Spawn: [ 0.90005723  0.36701658 -0.15326552  0.17806038]\n",
      "[INFO] [1662250729.927314, 3050.149000]: Waiting for service /gazebo/spawn_sdf_model\n",
      "[INFO] [1662250729.932736, 3050.149000]: Calling service /gazebo/spawn_sdf_model\n",
      "[INFO] [1662250730.203458, 3050.229000]: Spawn status: SpawnModel: Successfully spawned entity\n"
     ]
    }
   ],
   "source": [
    "num_objs=3\n",
    "x_gaz,y_gaz= 0,1.21\n",
    "\n",
    "\n",
    "for i in range(num_objs):\n",
    "    eu_i,eu_j,eu_k = np.random.rand(3)*np.pi\n",
    "    spawn_object('spawned'+str(i),objs[-33], x_gaz+0.1*np.random.randn(),  y_gaz+0.1*np.random.randn(),  0.71+0.1*np.random.randn(),eu_i,eu_j,eu_k )\n",
    " \n",
    "\n",
    "\n",
    "#NO GRAV\n",
    "#for i in range(num_objs):\n",
    "#    eu_i,eu_j,eu_k = np.random.rand(3)*np.pi\n",
    "#    spawn_object('spawned'+str(i),objs[-1], x_gaz+0.1*np.random.randn(),  y_gaz+0.1*np.random.randn(),  0.71+0.1*np.random.randn(),eu_i,eu_j,eu_k )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1662250731.168762906, 3050.500000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3050.500000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250731.170979275, 3050.500000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3050.500000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250731.171088343, 3050.500000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3050.500000 according to authority /pose_integrator\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADMAAAAzCAYAAAA6oTAqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAADMElEQVRoge2aTW/bRhCGn9mlKNOOZLe20YNhF0UPbYqgQG7+B/3r/hE9pC1apP5AXFUSRe7uTA9L2T0EuZBBCIMvoK8lAc7Dd2Z2l5CYGS9F7ksHMKQmmLFqghmrik8dvL6+HmWru7m5kY+NvyhnJpixaoIZqyaYsWqCGas+uQLoow8nb3h8uKNcnOPLQ8TPEMDMONq8I4WGY30Y9JqDw6yPLmlOfwKNpL9+Q5Ye50sgr4xEhM3Rt2hscbVnEW4Hu/bgMM3pj+zu3mGqLK9+RsRhZmDCExCC8yXr6nKcMP9WFzxsEl/ND1lc/ICGllhvYL8tl/yWwfKY8yV/Vm8o6lu+oT/UYA3g9nHN8vu3uKLEDEwVAENABBGhIwJ5+ob4grZYsrOydwyDwPz9uOX4u7cU1bK784qZgjikeyEuQ9FBdUAiDvEFjxz3jmOQNPOvf2F2dIxzDk0R1dQ507niJKeWGSYCyXL5SK4fcZ7GHe5L6svCOOeR3HeBfU3sHcgpth8BoPsNhqH5fHG9YQZJMzPFNGEanxwA/lcrDsHR+fA8bjyfb9o7jkGcsRSw2GAiaNSn4peuTqALvnNPVHIqpoCmFo0tGpre0QzijIYGSxHdB5cCpgnovBDJ00yXaKoR05g/U8Q0YCn0jmMQZ1Jb42ZzvDgsRizGXDoenCvYQ5gpGltQxfYgMaChyePzfnEMM2l++J0mthTVKzCHJcUA5+eo89186dCwY/v+V6qzq+xibIn1ihRqwnYFR/3CGQTmxG25rVeA4VyJ7tuy5i4lHVCqVxTVAo1NhgkNGnak3Zqzqv9TrUFgKm8UuxVBDT87wNRAPMwMcR4Th6nS/POecnGGht2zM80GjS3nZwe94xhsbXZx0FCnwB/3mpf7rsCXVTd/KGH9QLk4I9YrNDSksENjw9cHxvlpfxAYeNVceeXARba7BsQ/r89SiyvmpLYGM1Jb5wZgcP5quBAG3wJcnRTcreF+kwjre2KzxRUls2qZU84AlMOZ4/Jk2I3uZ9lpnr8qujs+BxYfOePz7NZf1DOACWasmmDGqglmrJpgxiqZ/jszUk0wY9UEM1a9KJj/AJNHmj4fyLRLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cents,xyz,imgs=seg_square_imgs(lower=100,plt_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images[] 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1662250790.033883467, 3073.179000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3073.179000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250790.033984829, 3073.179000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3073.179000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250790.039287913, 3073.179000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3073.179000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250801.969911590, 3077.841000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3077.875000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250801.970604606, 3077.841000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3077.875000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250801.970657212, 3077.841000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3077.875000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250802.247489642, 3077.954000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3078.050000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250802.247565211, 3077.954000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3078.050000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250802.248010675, 3078.050000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3078.050000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250810.242568505, 3081.259000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3081.259000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250810.242637233, 3081.259000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3081.259000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250810.243438016, 3081.259000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3081.259000 according to authority unknown_publisher\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "static_tf_publish(cents,label='coords 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_spawned(num_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1662250824.145344699, 3086.499000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3086.499000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250824.145502459, 3086.499000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3086.499000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250824.148151576, 3086.499000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3086.499000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250829.543642586, 3088.601000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3088.644000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250829.543719876, 3088.601000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3088.644000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250829.546200069, 3088.601000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3088.644000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250831.253008726, 3089.279000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3089.279000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250831.255724276, 3089.279000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3089.279000 according to authority /pose_integrator\u001b[0m\n",
      "\u001b[33m[ WARN] [1662250831.255783214, 3089.279000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame odom at time 3089.279000 according to authority /pose_integrator\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move_base(5.2,-2.7,0,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm.set_named_target('go')\n",
    "arm.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hv= head.get_current_joint_values()\n",
    "hv[1]=-.7\n",
    "head.go(hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53100/4241381817.py:82: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return(cents,np.asarray(points), images)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cents,xyz,imgs=seg_square_imgs(lower=100,plt_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images[] 0\n",
      "images[] 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_tf_publish(cents, label='coords2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nbTranslate": {
   "displayLangs": [
    "ja"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "ja",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
